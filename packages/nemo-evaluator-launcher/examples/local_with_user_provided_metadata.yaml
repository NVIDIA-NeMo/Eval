# Run with: nv-eval run --config-dir examples --config-name local_with_user_provided_metadata

defaults:
  - execution: local
  - deployment: none
  - _self_

execution:
  output_dir: llama_3_1_8b_instruct_results

# Optional user-provided metadata to be included in the logs
user_provided_metadata:
  experiment: "ablations-0820"
  run_note: "limit_samples smoke test"
  tags: ["dev", "limit10"]

target:
  api_endpoint:
    model_id: meta/llama-3.1-8b-instruct
    url: https://integrate.api.nvidia.com/v1/chat/completions
    api_key_name: API_KEY

evaluation:
  overrides:
    config.params.request_timeout: 3600
    config.params.limit_samples: 10
    target.api_endpoint.adapter_config.use_reasoning: false
    target.api_endpoint.adapter_config.use_system_prompt: true
    target.api_endpoint.adapter_config.custom_system_prompt: >-
      "Think step by step."
  tasks:
    - name: gpqa_diamond
      env_vars:
        HF_TOKEN: HF_TOKEN_FOR_GPQA_DIAMOND
