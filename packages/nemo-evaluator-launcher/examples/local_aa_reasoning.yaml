# SPDX-FileCopyrightText: Copyright (c) 2025, NVIDIA CORPORATION. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# How to use: copy this file locally into a directory, say `examples`, and run
# Run this config with `nemo-evaluator-launcher run --config-dir examples --config-name local_aa_reasoning`.

defaults:
  - execution: local
  - deployment: none
  - _self_

execution:
  output_dir: ??? # Set the output directory for your experiments; each `nemo-evaluator-launcher run` invocation will create a subdirectory

  # OPTIONAL: export results to mlflow; comment out if not needed
  # install mlflow with `pip install nemo-evaluator-launcher-internal[mlflow] --index-url https://gitlab-master.nvidia.com/api/v4/projects/155749/packages/pypi/simple`
  auto_export:
    destinations: ["mlflow"]
    configs:
      mlflow:
        tracking_uri: http://10.64.49.50:5003
        experiment_name: seminalysis_${target.api_endpoint.model_id}
        description: "Evaluation for semianalysis"
        tags:
          framework: "vLLM"
          precision: "bf16"
          tags: "test"

target:
  api_endpoint:
    model_id: deepseek-ai/deepseek-r1
    url: https://integrate.api.nvidia.com/v1/chat/completions
    api_key_name: NGC_API_KEY

evaluation:
  overrides: # these overrides apply to all tasks; for task-specific overrides, use the `overrides` field
    config.params.parallelism: 4 # Number of concurrent requests per each benchmark
    config.params.request_timeout: 3600
    config.params.max_retries: 10
    config.params.max_new_tokens: 65536
    config.params.temperature: 0.6
    config.params.top_p: 0.95
    target.api_endpoint.adapter_config.use_nvcf: true
    target.api_endpoint.adapter_config.use_reasoning: true # strips off reasoning part before evaluating a response
    # Uncomment below overrides if using Llama Nemotron family of models - turns on thinking
    # target.api_endpoint.adapter_config.use_system_prompt: true
    # target.api_endpoint.adapter_config.custom_system_prompt: >-
    #   "detailed thinking on"
  tasks:
    - name: livecodebench_0724_0125
      overrides: # task-specific overrides
        config.params.extra.num_process_evaluate: 10 # number of processes for the code evaluation phase; memory heavy

    - name: aa_scicode
      overrides:
        target.api_endpoint.adapter_config.include_if_reasoning_not_finished: false # if reasoning hasn't finished, returns empty string; otherwise, overflows max context length

    - name: AA_math_test_500
      env_vars:
        JUDGE_API_KEY: JUDGE_API_KEY_AA_MATH_TEST_500 # An api key for https://build.nvidia.com/meta/llama-3_3-70b-instruct

    - name: AA_AIME_2024
      env_vars:
        JUDGE_API_KEY: JUDGE_API_KEY_FOR_AA_AIME_2024 # An api key for https://build.nvidia.com/meta/llama-3_3-70b-instruct

    - name: mmlu_pro

    - name: hle
      env_vars:
        HF_TOKEN: HF_TOKEN_FOR_HLE # Click request access for HLE: https://huggingface.co/datasets/cais/hle
        OPENAI_CLIENT_ID: OPENAI_CLIENT_ID_FOR_HLE # the key must have access to gpt-4o
        OPENAI_CLIENT_SECRET: OPENAI_CLIENT_SECRET_FOR_HLE # the key must have access to gpt-4o

    - name: gpqa_diamond_aa_v2
      env_vars:
        HF_TOKEN: HF_TOKEN_FOR_GPQA_DIAMOND # Click request access for GPQA-Diamond: https://huggingface.co/datasets/Idavidrein/gpqa
