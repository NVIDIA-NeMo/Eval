

<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Evaluate NeMo 2.0 Checkpoints &#8212; NeMo Eval</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="_static/styles/nvidia-sphinx-theme.css?v=df3ac72c" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=01f34227"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'evaluation-doc';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_version = '0.16.1';
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = '../versions1.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '0.1.0';
        DOCUMENTATION_OPTIONS.show_version_warning_banner =
            false;
        </script>
    <link rel="icon" href="_static/favicon.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Evaluation Adapters" href="evaluation-adapters.html" />
    <link rel="prev" title="NeMo Eval" href="index.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />


    <script src="https://assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js" ></script>
    


  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="NeMo Eval - Home"/>
    <img src="_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="NeMo Eval - Home"/>
  
  
    <p class="title logo__title">NeMo Eval</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">


<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-2"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-2"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-2"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-2">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        



  
    
  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/nvidia-logo-horiz-rgb-blk-for-screen.svg" class="logo__image only-light" alt="NeMo Eval - Home"/>
    <img src="_static/nvidia-logo-horiz-rgb-wht-for-screen.svg" class="logo__image only-dark pst-js-only" alt="NeMo Eval - Home"/>
  
  
    <p class="title logo__title">NeMo Eval</p>
  
</a>


  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">


<div class="version-switcher__container dropdown pst-js-only">
  <button id="pst-version-switcher-button-3"
    type="button"
    class="version-switcher__button btn btn-sm dropdown-toggle"
    data-bs-toggle="dropdown"
    aria-haspopup="listbox"
    aria-controls="pst-version-switcher-list-3"
    aria-label="Version switcher list"
  >
    Choose version  <!-- this text may get changed later by javascript -->
    <span class="caret"></span>
  </button>
  <div id="pst-version-switcher-list-3"
    class="version-switcher__menu dropdown-menu list-group-flush py-0"
    role="listbox" aria-labelledby="pst-version-switcher-button-3">
    <!-- dropdown will be populated by javascript on page load -->
  </div>
</div></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">



<nav class="bd-docs-nav bd-links"
     aria-label="Table of Contents">
  <p class="bd-links__title" role="heading" aria-level="1">Table of Contents</p>
  <div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Basic Usage</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Evaluate NeMo 2.0 Checkpoints</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="evaluation-adapters.html">Evaluation Adapters</a></li>
<li class="toctree-l1"><a class="reference internal" href="logprobs.html">Evaluate LLMs Using Log-Probabilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="custom-task.html">Run Evaluation Using Task Without Pre-Defined Config</a></li>
<li class="toctree-l1"><a class="reference internal" href="scripts.html">Add On-Demand Evaluation Packages</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Development</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="documentation.html">Build and Test the Documentation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="apidocs/index.html">API Reference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="apidocs/nemo_eval/nemo_eval.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nemo_eval</span></code></a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="apidocs/nemo_eval/nemo_eval.utils.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nemo_eval.utils</span></code></a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="apidocs/nemo_eval/nemo_eval.utils.ray_deploy.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nemo_eval.utils.ray_deploy</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="apidocs/nemo_eval/nemo_eval.utils.api.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nemo_eval.utils.api</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="apidocs/nemo_eval/nemo_eval.utils.base.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nemo_eval.utils.base</span></code></a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="apidocs/nemo_eval/nemo_eval.adapters.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nemo_eval.adapters</span></code></a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="apidocs/nemo_eval/nemo_eval.adapters.interceptors.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nemo_eval.adapters.interceptors</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="apidocs/nemo_eval/nemo_eval.adapters.server.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nemo_eval.adapters.server</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="apidocs/nemo_eval/nemo_eval.adapters.utils.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nemo_eval.adapters.utils</span></code></a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="apidocs/nemo_eval/nemo_eval.api.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nemo_eval.api</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="apidocs/nemo_eval/nemo_eval.package_info.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nemo_eval.package_info</span></code></a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>



      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Evaluate NeMo 2.0 Checkpoints</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="evaluate-nemo-2-0-checkpoints">
<h1>Evaluate NeMo 2.0 Checkpoints<a class="headerlink" href="#evaluate-nemo-2-0-checkpoints" title="Link to this heading">#</a></h1>
<p>This guide provides detailed instructions on evaluating NeMo 2.0 checkpoints using the <a class="reference external" href="https://pypi.org/project/nvidia-lm-eval/">NVIDIA Evals Factory</a> within the NeMo Framework.</p>
<p>In this section we will focus on benchmarks that use <strong>generation</strong>.
In such approach the model is presented with a question it needs to answer, an instruction it should follow, or a text that it should continue.
Then the model’s answer is evaluated for its correctness.</p>
<p>Supported benchmarks include:</p>
<ul class="simple">
<li><p>GPQA</p></li>
<li><p>GSM8K</p></li>
<li><p>IFEval</p></li>
<li><p>MGSM</p></li>
<li><p>MMLU</p></li>
<li><p>MMLU-Pro</p></li>
<li><p>MMLU-Redux</p></li>
<li><p>Wikilingua</p></li>
</ul>
<p>An alternative approach to LLM evaluation utilizes <strong>log-probabilities</strong>.
To learn more please refer to <a class="reference internal" href="logprobs.html"><span class="std std-doc">“Evaluate LLMs Using Log-Probabilities”</span></a></p>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>The evaluation process employs a server-client approach, comprising two main phases. In Phase 1, the NeMo 2.0 checkpoint is deployed in-framework on a PyTriton server by exposing OpenAI API (OAI) compatible endpoints. Both completions (<code class="docutils literal notranslate"><span class="pre">v1/completions</span></code>) and chat-completions (<code class="docutils literal notranslate"><span class="pre">v1/chat/completions</span></code>) endpoints are exposed, enabling evaluation on both completion and chat benchmarks. Phase 2 involves running the evaluation on the model using the OAI endpoint and port.</p>
<p>Some of the benchmarks (e.g. GPQA) use a gated dataset. To use them, you must authenticate to the <a class="reference external" href="https://huggingface.co/docs/huggingface_hub/quick-start#authentication">Hugging Face Hub</a> before launching the evaluation.</p>
<p>The NVIDIA Evals Factory provides several evaluation harnesses with different sets of evaluation benchmarks. The <a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/nemo">NeMo Framework container</a> includes <code class="docutils literal notranslate"><span class="pre">nvidia-lm-eval</span></code> pre-installed, along with predefined configurations for evaluating the completions endpoint:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">gsm8k</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mgsm</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mmlu</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mmlu_pro</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mmlu_redux</span></code></p></li>
</ul>
<p>It also provides the following configurations for evaluating the chat endpoint:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">gpqa_diamond_cot</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">gsm8k_cot_instruct</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ifeval</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mgsm_cot</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mmlu_instruct</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mmlu_pro_instruct</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mmlu_redux_instruct</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">wikilingua</span></code></p></li>
</ul>
<p>When specifying the task, you can either use the task name from the list above or prepend it with the harness name. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">task</span> <span class="o">=</span> <span class="s2">&quot;mmlu&quot;</span>
<span class="n">task</span> <span class="o">=</span> <span class="s2">&quot;lm-evaluation-harness.mmlu&quot;</span>
<span class="n">task</span> <span class="o">=</span> <span class="s2">&quot;lm_evaluation_harness.mmlu&quot;</span>
</pre></div>
</div>
<p>To enable other evaluation harnesses, you need to install them. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>nvidia-simple-evals
</pre></div>
</div>
<p>If multiple harnesses define a task with the same name, you must use the <code class="docutils literal notranslate"><span class="pre">&lt;harness&gt;.&lt;task&gt;</span></code> format to avoid ambiguity. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">task</span> <span class="o">=</span> <span class="s2">&quot;lm-evaluation-harness.mmlu&quot;</span>
<span class="n">task</span> <span class="o">=</span> <span class="s2">&quot;simple-evals.mmlu&quot;</span>
</pre></div>
</div>
<p>For more information on enablind additional evaluation harnesses, see <a class="reference internal" href="scripts.html"><span class="std std-doc">“Add On-Demand Evaluation Packages”</span></a> section.
To evaluate your model on a task without pre-defined config, see <a class="reference internal" href="custom-task.html"><span class="std std-doc">“Run Evaluation Using Task Without Pre-Defined Config”</span></a></p>
</section>
<section id="run-evaluations-without-nemo-run">
<h2>Run Evaluations without NeMo-Run<a class="headerlink" href="#run-evaluations-without-nemo-run" title="Link to this heading">#</a></h2>
<p>This section outlines the steps to deploy and evaluate a NeMo 2.0 model directly using Python commands, without using NeMo-Run. This method is quick and easy, making it ideal for evaluation on a local workstation with GPUs, as it facilitates easier debugging. However, for running evaluations on clusters, it is recommended to use NeMo-Run for its ease of use.</p>
<p>The entry point for deployment is the <code class="docutils literal notranslate"><span class="pre">deploy</span></code> method defined in <code class="docutils literal notranslate"><span class="pre">nemo/collections/llm/api.py</span></code>. Below is an example command for deployment. It uses a Hugging Face LLaMA 3 8B checkpoint that has been converted to NeMo 2.0 format. To evaluate a checkpoint saved during <a class="reference external" href="https://docs.nvidia.com/nemo-framework/user-guide/latest/nemo-2.0/quickstart.html#pretraining">pretraining</a> or <a class="reference external" href="https://docs.nvidia.com/nemo-framework/user-guide/latest/nemo-2.0/quickstart.html#fine-tuning">fine-tuning</a> using the NeMo Framework, provide the path to the saved checkpoint using the <code class="docutils literal notranslate"><span class="pre">nemo_checkpoint</span></code> argument in the <code class="docutils literal notranslate"><span class="pre">deploy</span></code> command below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nemo.collections.llm</span><span class="w"> </span><span class="kn">import</span> <span class="n">deploy</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">deploy</span><span class="p">(</span>
        <span class="n">nemo_checkpoint</span><span class="o">=</span><span class="s1">&#39;/workspace/llama3_8b_nemo2&#39;</span><span class="p">,</span>
        <span class="n">max_input_len</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
        <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">num_gpus</span><span class="o">=</span><span class="mi">1</span><span class="p">,)</span>
</pre></div>
</div>
<p>The entrypoint for evaluation is the <code class="docutils literal notranslate"><span class="pre">evaluate</span></code> method defined in <code class="docutils literal notranslate"><span class="pre">nemo/collections/llm/api.py</span></code>. To run evaluations on the deployed model, use the following command. Make sure to open a new terminal within the same container to execute it. For longer evaluations, it is advisable to run both the deploy and evaluate commands in tmux sessions to prevent the processes from being terminated unexpectedly and aborting the runs.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">nemo.collections.llm</span><span class="w"> </span><span class="kn">import</span> <span class="n">evaluate</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">nemo.collections.llm.evaluation.api</span><span class="w"> </span><span class="kn">import</span> <span class="n">EvaluationConfig</span><span class="p">,</span> <span class="n">ApiEndpoint</span><span class="p">,</span> <span class="n">EvaluationTarget</span><span class="p">,</span> <span class="n">ConfigParams</span>

<span class="n">api_endpoint</span> <span class="o">=</span> <span class="n">ApiEndpoint</span><span class="p">()</span>
<span class="n">eval_target</span> <span class="o">=</span> <span class="n">EvaluationTarget</span><span class="p">(</span><span class="n">api_endpoint</span><span class="o">=</span><span class="n">api_endpoint</span><span class="p">)</span>
<span class="n">eval_params</span> <span class="o">=</span> <span class="n">ConfigParams</span><span class="p">(</span><span class="n">top_p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">limit_samples</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">parallelism</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">eval_config</span> <span class="o">=</span> <span class="n">EvaluationConfig</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s1">&#39;mmlu&#39;</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">eval_params</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">evaluate</span><span class="p">(</span><span class="n">target_cfg</span><span class="o">=</span><span class="n">eval_target</span><span class="p">,</span> <span class="n">eval_cfg</span><span class="o">=</span><span class="n">eval_config</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><p><strong>Note:</strong> Please refer to <code class="docutils literal notranslate"><span class="pre">deploy</span></code> and <code class="docutils literal notranslate"><span class="pre">evaluate</span></code> method in <code class="docutils literal notranslate"><span class="pre">nemo/collections/llm/api.py</span></code> to review all available argument options, as the provided commands are only examples and do not include all arguments or their default values. For more detailed information on the arguments used in the ApiEndpoint and ConfigParams classes for evaluation, see the source code at <a class="reference external" href="https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/llm/evaluation/api.py">nemo/collections/llm/evaluation/api.py</a>.</p>
</div></blockquote>
</section>
<section id="run-evaluations-with-nemo-run">
<h2>Run Evaluations with NeMo-Run<a class="headerlink" href="#run-evaluations-with-nemo-run" title="Link to this heading">#</a></h2>
<p>This section explains how to run evaluations with NeMo-Run. For detailed information about <a class="reference external" href="https://github.com/NVIDIA/NeMo-Run">NeMo-Run</a>, please refer to its documentation. Below is a concise guide focused on using NeMo-Run to perform evaluations in NeMo 2.0.</p>
</section>
<section id="launch-evaluations-with-nemo-run">
<h2>Launch Evaluations with NeMo-Run<a class="headerlink" href="#launch-evaluations-with-nemo-run" title="Link to this heading">#</a></h2>
<p>The <a class="reference external" href="https://github.com/NVIDIA/NeMo/blob/main/scripts/llm/evaluation.py">evaluation.py</a> script serves as a reference for launching evaluations with NeMo-Run. This script demonstrates how to use NeMo-Run with both local executors (your local workstation) and Slurm-based executors like clusters. In this setup, the deploy and evaluate processes are launched as two separate jobs with NeMo-Run. The evaluate method waits until the PyTriton server is accessible and the model is deployed before starting the evaluations.</p>
<blockquote>
<div><p><strong>Note:</strong> Please make sure to update HF_TOKEN in the NeMo-Run script’s <a class="reference external" href="https://github.com/NVIDIA/NeMo/blob/main/scripts/llm/evaluation.py#L210">local_executor env_vars</a> with your HF_TOKEN if using local executor or in the <a class="reference external" href="https://github.com/NVIDIA/NeMo/blob/main/scripts/llm/evaluation.py#L177">slurm_executor’s env_vars</a> if using slurm_executor.</p>
</div></blockquote>
</section>
<section id="run-locally-with-nemo-run">
<h2>Run Locally with NeMo-Run<a class="headerlink" href="#run-locally-with-nemo-run" title="Link to this heading">#</a></h2>
<p>To run evaluations on your local workstation, use the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>scripts/llm/evaluation.py<span class="w"> </span>--nemo_checkpoint<span class="w"> </span><span class="s1">&#39;/workspace/llama3_8b_nemo2/&#39;</span><span class="w"> </span>--eval_task<span class="w"> </span><span class="s1">&#39;gsm8k&#39;</span><span class="w"> </span>--devices<span class="w"> </span><span class="m">2</span>
</pre></div>
</div>
<blockquote>
<div><p><strong>Note:</strong> When running locally with NeMo-Run, you will need to manually terminate the deploy process once evaluations are complete.</p>
</div></blockquote>
</section>
<section id="run-on-slurm-based-clusters">
<h2>Run on Slurm-based Clusters<a class="headerlink" href="#run-on-slurm-based-clusters" title="Link to this heading">#</a></h2>
<p>To run evaluations on Slurm-based clusters, add the <code class="docutils literal notranslate"><span class="pre">--slurm</span></code> flag to your command and specify any custom parameters such as user, host, remote_job_dir, account, mounts, etc. Refer to the evaluation.py script for further details. Below is an example command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>scripts/llm/evaluation.py<span class="w"> </span>--nemo_checkpoint<span class="o">=</span><span class="s1">&#39;/workspace/llama3_8b_nemo2&#39;</span><span class="w"> </span>--slurm<span class="w"> </span>--nodes<span class="w"> </span><span class="m">1</span>
--devices<span class="w"> </span><span class="m">8</span><span class="w"> </span>--container_image<span class="w"> </span><span class="s2">&quot;nvcr.io/nvidia/nemo:25.04&quot;</span><span class="w"> </span>--tensor_parallelism_size<span class="w"> </span><span class="m">8</span>
</pre></div>
</div>
<p>By following these commands, you can successfully run evaluations using NeMo-Run on both local and Slurm-based environments.</p>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">NeMo Eval</p>
      </div>
    </a>
    <a class="right-next"
       href="evaluation-adapters.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Evaluation Adapters</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            


              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#run-evaluations-without-nemo-run">Run Evaluations without NeMo-Run</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#run-evaluations-with-nemo-run">Run Evaluations with NeMo-Run</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#launch-evaluations-with-nemo-run">Launch Evaluations with NeMo-Run</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#run-locally-with-nemo-run">Run Locally with NeMo-Run</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#run-on-slurm-based-clusters">Run on Slurm-based Clusters</a></li>
</ul>
  </nav></div>

</div></div>
              
            

          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
<a class="footer-brand logo" href="https://www.nvidia.com">
  <img src="_static/nvidia-logo-horiz-rgb-1c-blk-for-screen.svg" class="logo__image only-light" alt="NVIDIA"/>
  <img src="_static/nvidia-logo-horiz-rgb-1c-wht-for-screen.svg" class="logo__image only-dark" alt="NVIDIA"/>
</a></div>
      
        <div class="footer-item">

<div class="footer-links">
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/">Privacy Policy</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/">Manage My Privacy</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/preferences/start/">Do Not Sell or Share My Data</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/">Terms of Service</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/accessibility/">Accessibility</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/about-nvidia/company-policies/">Corporate Policies</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/product-security/">Product Security</a>
   | 
  
  
  
  <a class="external" href="https://www.nvidia.com/en-us/contact/">Contact</a>
  
  
  
</div>
</div>
      
        <div class="footer-item">




  <p class="copyright">
    
      Copyright © 2025, NVIDIA Corporation.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">
<div class="extra_footer">
  
  
    <script type="text/javascript">if (typeof _satellite !== "undefined") {_satellite.pageBottom();}</script>
    
  
</div></div>
      
    </div>
  
  
  
</div>

  </footer>
  </body>
</html>